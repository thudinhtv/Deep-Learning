{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Mnist_Fashion_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj12sQWRZNAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras import optimizers\n",
        "from keras import callbacks\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGsmt1h9aE7u",
        "colab_type": "code",
        "outputId": "6f392e8c-25da-4abd-9c21-8f2607c232bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://ed594550.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htORZ4HgZaPk",
        "colab_type": "text"
      },
      "source": [
        "## **Get and inpect data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g4kXZGgZcy9",
        "colab_type": "code",
        "outputId": "0e154675-5173-4551-a321-d7475dbb7fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist_fashion = input_data.read_data_sets(\"/notebooks/data/fashion_mnist/\", reshape=False, one_hot=True)\n",
        "X_train = mnist_fashion.train.images\n",
        "Y_train = mnist_fashion.train.labels\n",
        "X_validation = mnist_fashion.validation.images\n",
        "Y_validation = mnist_fashion.validation.labels\n",
        "X_test = mnist_fashion.test.images\n",
        "Y_test = mnist_fashion.test.labels\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-32ab67afbd9b>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /notebooks/data/fashion_mnist/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /notebooks/data/fashion_mnist/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /notebooks/data/fashion_mnist/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /notebooks/data/fashion_mnist/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93JrqLWUZnuA",
        "colab_type": "code",
        "outputId": "2d2f503c-22c2-4d43-89a7-675ae72bf957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(mnist_fashion.validation.labels[:1])\n",
        "print('Training set', X_train.shape, Y_train.shape)\n",
        "print('Validation set', X_validation.shape, Y_validation.shape)\n",
        "print('Test set', X_test.shape, Y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "Training set (55000, 28, 28, 1) (55000, 10)\n",
            "Validation set (5000, 28, 28, 1) (5000, 10)\n",
            "Test set (10000, 28, 28, 1) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO8tZJT4ZtFY",
        "colab_type": "text"
      },
      "source": [
        "## **Build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnlgJq_HZvjm",
        "colab_type": "code",
        "outputId": "4b9cc8c6-2ba5-41a1-fcaf-ab631dd852bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "source": [
        "# Model 1 (step g)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), strides=2, activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=1))\n",
        "model.add(Conv2D(128, (3, 3), strides=1, kernel_initializer='glorot_uniform'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(20, activation='elu', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary() "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 9, 128)         36992     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                207380    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 20)                80        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 244,982\n",
            "Trainable params: 244,942\n",
            "Non-trainable params: 40\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHJta80GNQ9_",
        "colab_type": "code",
        "outputId": "62271714-bd87-4c23-86db-e187173cc9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "# Choose loss function and optimizer\n",
        "adam = optimizers.Adam(lr=.01)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "# Train the model\n",
        "network_history = model.fit(X_train, Y_train, batch_size=50, epochs=1, verbose=1, validation_data=(X_validation, Y_validation), callbacks=[TensorBoardColabCallback(tbc)])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 55000 samples, validate on 5000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 43s 785us/step - loss: 0.1480 - acc: 0.9555 - val_loss: 0.1440 - val_acc: 0.9560\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/callbacks.py:51: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb-BPMOCydVw",
        "colab_type": "code",
        "outputId": "1ce7b1b4-b2e5-419d-9d64-6bdd947e4ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "# Model 2 (step m)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), strides=2, activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=1))\n",
        "model.add(Conv2D(128, (3, 3), strides=1, kernel_initializer='glorot_uniform'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(20, activation='elu', kernel_initializer='glorot_uniform'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary() \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 128)         36992     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                207380    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 20)                80        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 244,982\n",
            "Trainable params: 244,942\n",
            "Non-trainable params: 40\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-MG_A6ZOe1C",
        "colab_type": "code",
        "outputId": "1eb1c00a-908d-4564-8ab5-03934301333e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Choose loss function and optimizer\n",
        "adam = optimizers.Adam(lr=.01)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "# Train the model\n",
        "network_history = model.fit(X_train, Y_train, batch_size=50, epochs=1, verbose=1, validation_data=(X_validation, Y_validation), callbacks=[TensorBoardColabCallback(tbc)])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 44s 802us/step - loss: 0.6509 - acc: 0.7818 - val_loss: 0.1300 - val_acc: 0.9632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUqd6DSxNN33",
        "colab_type": "code",
        "outputId": "811b092c-0231-47cc-eba0-0550c652b613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "# Model 3 (step q)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), strides=2, activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=1))\n",
        "model.add(Conv2D(128, (3, 3), strides=1, activation='linear', use_bias = False, kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(20, activation='elu', kernel_initializer='glorot_uniform'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary() "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_3 (Average (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 9, 9, 128)         36864     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 9, 9, 128)         512       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                207380    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 20)                80        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 245,366\n",
            "Trainable params: 245,070\n",
            "Non-trainable params: 296\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBrbXFR6MxOi",
        "colab_type": "code",
        "outputId": "3d96a24c-219b-44a4-f003-c1c7ea6eaa69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "## **Choose loss function and optimizer**\n",
        "adam = optimizers.Adam(lr=.01)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "## **Train the model**\n",
        "network_history = model.fit(X_train, Y_train, batch_size=50, epochs=1, verbose=1, validation_data=(X_validation, Y_validation), callbacks=[TensorBoardColabCallback(tbc)])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 56s 1ms/step - loss: 0.5842 - acc: 0.8012 - val_loss: 0.1133 - val_acc: 0.9722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLSiivFGNrUY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej_PY4xDyeDs",
        "colab_type": "code",
        "outputId": "8aac71e4-f2fd-46d9-ebc1-eae1df0c8bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "# Model 4 (step u)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), strides=2, activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=1))\n",
        "model.add(Conv2D(128, (3, 3), strides=1, activation='linear', use_bias = False, kernel_initializer='glorot_uniform'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(20, activation='elu', kernel_initializer='glorot_uniform'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary() "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_4 (Average (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 9, 9, 128)         36864     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 128)         512       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 20)                207380    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 20)                80        \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 245,366\n",
            "Trainable params: 245,070\n",
            "Non-trainable params: 296\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj7YgQZ9yeig",
        "colab_type": "code",
        "outputId": "548d44ee-1c1a-44ba-d09e-a70ee1d71d85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "## **Choose loss function and optimizer**\n",
        "adam = optimizers.Adam(lr=.01)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
        "## **Train the model**\n",
        "network_history = model.fit(X_train, Y_train, batch_size=50, epochs=1, verbose=1, validation_data=(X_validation, Y_validation), callbacks=[TensorBoardColabCallback(tbc)])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 65s 1ms/step - loss: 0.5927 - acc: 0.8017 - val_loss: 0.1191 - val_acc: 0.9698\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}