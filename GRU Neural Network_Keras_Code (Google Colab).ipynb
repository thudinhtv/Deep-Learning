{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exe11_Draft2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnLt9zIu1OTs",
        "colab_type": "code",
        "outputId": "8b4e4ada-8ee8-4e0c-9f9d-b5d2fa48a9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "import os, sys\n",
        "import glob\n",
        "import shutil\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import hashlib\n",
        "from typing import Sequence, Tuple, TypeVar, Union\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import re\n",
        "import pickle\n",
        "import requests\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "from numpy import array\n",
        "from numpy.random import random, permutation, randn, normal, uniform, choice\n",
        "from keras import applications\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
        "from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
        "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image, sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn.manifold\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4nHGnwK2Kl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0tYR0DF2OrS",
        "colab_type": "code",
        "outputId": "c62e0809-2554-4d49-cb9b-4d5048456bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypMHDQh_y4RY",
        "colab_type": "code",
        "outputId": "36867b97-0850-4a89-d10b-f56c0b08c84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install myutils\n",
        "from myutils import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting myutils\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/1a/8a4890f87e4a3866b9467bf09e4b4aedef15a3c1657436ee44a087ed9c8d/myutils-0.0.21.zip\n",
            "Building wheels for collected packages: myutils\n",
            "  Building wheel for myutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for myutils: filename=myutils-0.0.21-cp36-none-any.whl size=1361 sha256=45fec45ac2c5bb3834ae5d06bfc3554446aafaaae811f214d722cb74bbe0084a\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/15/15/1b5ef18349eaee0cf7a3bf369ab61667a871e534e9928aa9e0\n",
            "Successfully built myutils\n",
            "Installing collected packages: myutils\n",
            "Successfully installed myutils-0.0.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGLIpm7Hb9hN",
        "colab_type": "text"
      },
      "source": [
        "### **Upload Data Sets to Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-gO_xh4iKXM",
        "colab_type": "code",
        "outputId": "72db5244-d8cc-49c8-92f8-26bb525bb9b3",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#Read from local drive (choose file when running)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-314f30fc-34be-4372-9a66-0563a4c7498e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-314f30fc-34be-4372-9a66-0563a4c7498e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Amazon_Product_Reviews.csv to Amazon_Product_Reviews.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMUIgBcJ2FVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to dataframe\n",
        "import io\n",
        "review_df = pd.read_csv(io.BytesIO(uploaded['Amazon_Product_Reviews.csv']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mAw-xhoBPkC",
        "colab_type": "text"
      },
      "source": [
        "# **Pre-process Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNC72UyuowES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "    text = text.replace('x', '')\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwords from text\n",
        "    return text\n",
        "review_df.Text = review_df.Text.apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh2peirEkf6c",
        "colab_type": "code",
        "outputId": "21749ddb-2d3c-40ff-f1b5-d606a2a5e051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "# a. Print the first ten observations\n",
        "review_df.info()\n",
        "review_df[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 650000 entries, 0 to 649999\n",
            "Data columns (total 2 columns):\n",
            "Text     650000 non-null object\n",
            "Label    650000 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 9.9+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model may ok sedentary types im active get aro...</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fast read filled unepected humour profound ins...</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bought one chargersthe instructions say lights...</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ecited find book ostensibly muslim feminism vo...</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>big jvc fan like model suspiscious saw several...</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>love style couple years dvd giving problems do...</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cannot scroll dvd menu set vertically triangle...</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>movie animals really keeps grandson occupied i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>found copy cookbook local used book store mied...</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>book basic book using sourdough author obvious...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text    Label\n",
              "0  model may ok sedentary types im active get aro...      Bad\n",
              "1  fast read filled unepected humour profound ins...     Good\n",
              "2  bought one chargersthe instructions say lights...      Bad\n",
              "3  ecited find book ostensibly muslim feminism vo...      Bad\n",
              "4  big jvc fan like model suspiscious saw several...      Bad\n",
              "5  love style couple years dvd giving problems do...      Bad\n",
              "6  cannot scroll dvd menu set vertically triangle...      Bad\n",
              "7  movie animals really keeps grandson occupied i...  Neutral\n",
              "8  found copy cookbook local used book store mied...     Good\n",
              "9  book basic book using sourdough author obvious...  Neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_4Q2Vdrmbv7",
        "colab_type": "code",
        "outputId": "4530ae98-5dff-4a37-beea-0430c5498d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# b. Create tokens with 50,000 as max number of words and filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n",
        "MAX_NB_WORDS = 50000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 100\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(review_df['Text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 612517 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-v0r-YPxRO4",
        "colab_type": "code",
        "outputId": "c3c7d163-1268-4b73-b35c-1c4ffa82f479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#c. Create padding sequence and limit the length to 250.\n",
        "X = tokenizer.texts_to_sequences(review_df['Text'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (650000, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K4Eug5dxwOe",
        "colab_type": "code",
        "outputId": "0ba1b2e8-7016-4c64-d97e-ce11984fb57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# d. Create one-hot representation of Rating class column.\n",
        "Y = pd.get_dummies(review_df['Label']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (650000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iFTp-Etyltw",
        "colab_type": "code",
        "outputId": "5890a2b9-b7c7-4f29-f1eb-421712c1dc9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#e. Partition the data into 70% training, 30% for testing datasets. Use Seed=802 for data partitioning.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.30, random_state = 802)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455000, 250) (455000, 3)\n",
            "(195000, 250) (195000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4NC-gIy0agt",
        "colab_type": "text"
      },
      "source": [
        "# **Building RRN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Y6C6kw0SPX",
        "colab_type": "code",
        "outputId": "2359f1d7-1b1f-4d2d-cd8b-d4075df19a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#f. Build a Recurrent unit neural network with one embedding layer, two LSTM hidden layers, and an output layer\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))         \n",
        "model.add(LSTM(100, activation='relu', kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform', return_sequences=True))\n",
        "model.add(LSTM(100, activation='relu', kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform'))\n",
        "model.add(Dense(Y.shape[1], activation='softmax'))\n",
        "# Note: The values for MAX_NB_WORDS, EMBEDDING_DIM, input_length were already set in step b. \n",
        "# Like kernel_initializer, the bias_initializer is also set to 'Xavier' to improve model performance. \n",
        "# (Without bias_initializer='glorot_uniform', the valid accuracy was only 0.39-0.40)\n",
        "# (Setting bias_initializer='glorot_uniform', the valid accuracy increased to nearly 0.70)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoxrW76s4gOH",
        "colab_type": "code",
        "outputId": "bea5b176-7e72-4a76-bf0a-e62049ec32b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# g. Compile the model \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 250, 100)          5000000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 250, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 5,161,103\n",
            "Trainable params: 5,161,103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6oJFwRb3w8v",
        "colab_type": "code",
        "outputId": "3a0d2a25-ed10-4d60-d517-0f719d3e376c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "# h. Fit model with 5 epochs, 1,000 batch size, 15% as validation split \n",
        "epochs = 5\n",
        "batch_size = 1000\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.15)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 386750 samples, validate on 68250 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "386750/386750 [==============================] - 292s 755us/step - loss: 0.8001 - acc: 0.6480 - val_loss: 0.7251 - val_acc: 0.6871\n",
            "Epoch 2/5\n",
            "386750/386750 [==============================] - 286s 738us/step - loss: 0.6791 - acc: 0.7102 - val_loss: 0.7034 - val_acc: 0.6991\n",
            "Epoch 3/5\n",
            "386750/386750 [==============================] - 285s 736us/step - loss: 0.6312 - acc: 0.7327 - val_loss: 0.7106 - val_acc: 0.6988\n",
            "Epoch 4/5\n",
            "386750/386750 [==============================] - 284s 734us/step - loss: 0.5815 - acc: 0.7553 - val_loss: 0.7283 - val_acc: 0.6970\n",
            "Epoch 5/5\n",
            "386750/386750 [==============================] - 285s 736us/step - loss: 0.5357 - acc: 0.7772 - val_loss: 0.7694 - val_acc: 0.6914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ-m6Mnc-9U1",
        "colab_type": "code",
        "outputId": "0a711374-1f0c-4c1d-8c0b-3cac0c236841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#i. Evaluate model with Test data and view the misclassification error\n",
        "accr = model.evaluate(X_test,Y_test, batch_size=1000)\n",
        "print('Test set\\n  Loss: {:0.9f}\\n  Accuracy: {:0.9f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195000/195000 [==============================] - 46s 234us/step\n",
            "Test set\n",
            "  Loss: 0.770831045\n",
            "  Accuracy: 0.690641025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deDXmk1D_puK",
        "colab_type": "code",
        "outputId": "82648670-7bfe-4931-864e-6465b6f927d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#j. Regularize the previous LSTM model by building the model again but include a dropout of 0.40 in each LSTM hidden layer. \n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model2.add(LSTM(100, activation='relu', kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform', return_sequences=True, dropout=0.4))\n",
        "model2.add(LSTM(100, activation='relu', kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform', dropout=0.4))\n",
        "model2.add(Dense(Y.shape[1], activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 250, 100)          5000000   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 250, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 5,161,103\n",
            "Trainable params: 5,161,103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhd1G00iAusD",
        "colab_type": "code",
        "outputId": "a9eee476-fb86-43ac-98bd-b9cb23f2006a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "## Train the new model with the same parameters as in previous model.\n",
        "epochs = 5\n",
        "batch_size = 1000\n",
        "history = model2.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.15)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 386750 samples, validate on 68250 samples\n",
            "Epoch 1/5\n",
            "386750/386750 [==============================] - 315s 815us/step - loss: 0.8755 - acc: 0.6155 - val_loss: 0.7886 - val_acc: 0.6687\n",
            "Epoch 2/5\n",
            "386750/386750 [==============================] - 313s 810us/step - loss: 1.2863 - acc: 0.6359 - val_loss: 0.8286 - val_acc: 0.6398\n",
            "Epoch 3/5\n",
            "386750/386750 [==============================] - 313s 810us/step - loss: 0.7807 - acc: 0.6673 - val_loss: 0.7677 - val_acc: 0.6714\n",
            "Epoch 4/5\n",
            "386750/386750 [==============================] - 314s 812us/step - loss: 0.4824 - acc: 0.5467 - val_loss: 1.1921e-07 - val_acc: 0.3983\n",
            "Epoch 5/5\n",
            "386750/386750 [==============================] - 313s 808us/step - loss: 1.1921e-07 - acc: 0.4002 - val_loss: 1.1921e-07 - val_acc: 0.3983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhOjszObBLDv",
        "colab_type": "code",
        "outputId": "dc3e3cd3-f0bb-470d-eada-ed2698524720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# k. Score the test data using the LSTM model with regularization\n",
        "accr2 = model2.evaluate(X_test,Y_test, batch_size=1000)\n",
        "print('Test set\\n  Loss: {:0.9f}\\n  Accuracy: {:0.9f}'.format(accr2[0],accr2[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195000/195000 [==============================] - 50s 256us/step\n",
            "Test set\n",
            "  Loss: 0.000000119\n",
            "  Accuracy: 0.400271795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSFiGkSFCBL4",
        "colab_type": "code",
        "outputId": "feccd7de-5ccf-4a91-d1a3-0a232d954e34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#l. Add a new LSTM layer after second LSTM hidden layer with 50 Neurons\n",
        "## and recurrent dropout .2 , dropout .3, and activation function Tanh. \n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model3.add(LSTM(100, activation='relu', kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform', return_sequences=True, dropout=0.4))\n",
        "model3.add(LSTM(100, activation='relu', kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform', return_sequences=True, dropout=0.4))\n",
        "model3.add(LSTM(50, activation='tanh', dropout=0.3, recurrent_dropout=0.2))\n",
        "model3.add(Dense(Y.shape[1], activation='softmax'))\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 250, 100)          5000000   \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 250, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 250, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 153       \n",
            "=================================================================\n",
            "Total params: 5,191,153\n",
            "Trainable params: 5,191,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRqVxoE8DJcy",
        "colab_type": "code",
        "outputId": "ff9a3aad-1e21-4688-b909-a5a635ca2e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#m. Compile and fit this model with parameters as above\n",
        "epochs = 5\n",
        "batch_size = 1000\n",
        "history = model3.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.15)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 386750 samples, validate on 68250 samples\n",
            "Epoch 1/5\n",
            "386750/386750 [==============================] - 490s 1ms/step - loss: 1.0099 - acc: 0.5043 - val_loss: 0.9342 - val_acc: 0.5792\n",
            "Epoch 2/5\n",
            "386750/386750 [==============================] - 486s 1ms/step - loss: 0.9787 - acc: 0.5291 - val_loss: 0.9315 - val_acc: 0.5797\n",
            "Epoch 3/5\n",
            "386750/386750 [==============================] - 486s 1ms/step - loss: 0.9784 - acc: 0.5289 - val_loss: 0.9417 - val_acc: 0.5766\n",
            "Epoch 4/5\n",
            "386750/386750 [==============================] - 484s 1ms/step - loss: 0.9781 - acc: 0.5289 - val_loss: 0.9451 - val_acc: 0.5718\n",
            "Epoch 5/5\n",
            "386750/386750 [==============================] - 484s 1ms/step - loss: 0.9776 - acc: 0.5280 - val_loss: 0.9409 - val_acc: 0.5738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuwQqwRlDAYs",
        "colab_type": "code",
        "outputId": "a6f0bfe4-ae92-44b3-fa45-aa00d7e0bbea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#n. Score the test data using the LSTM model with regularization\n",
        "accr3 = model3.evaluate(X_test,Y_test, batch_size=1000)\n",
        "print('Test set\\n  Loss: {:0.9f}\\n  Accuracy: {:0.9f}'.format(accr3[0],accr3[1]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195000/195000 [==============================] - 76s 391us/step\n",
            "Test set\n",
            "  Loss: 0.940462362\n",
            "  Accuracy: 0.573774358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlY8cExWDduM",
        "colab_type": "code",
        "outputId": "503d6fa4-3d8b-4ded-d626-21b0ee926a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#o. Add new GRU layer before output layers with 70 Neurons and Relu as activation function \n",
        "## and Tanh as recurrent activation function.\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model4.add(LSTM(100, activation='relu', kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform', return_sequences=True, dropout=0.4))\n",
        "model4.add(LSTM(100, activation='relu', kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform', return_sequences=True, dropout=0.4))\n",
        "model4.add(LSTM(50, activation='tanh', return_sequences=True, dropout=0.3, recurrent_dropout=0.2))\n",
        "model4.add(GRU(70, activation='relu', recurrent_activation='tanh'))\n",
        "model4.add(Dense(Y.shape[1], activation='softmax'))\n",
        "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model4.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 250, 100)          5000000   \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 250, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 250, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 250, 50)           30200     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 70)                25410     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 213       \n",
            "=================================================================\n",
            "Total params: 5,216,623\n",
            "Trainable params: 5,216,623\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLfrQqhyFMi2",
        "colab_type": "code",
        "outputId": "4c5c6266-b4a5-400e-d0e3-9e9e9536e94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#p. Compile and fit this model with parameters as above.\n",
        "epochs = 5\n",
        "batch_size = 1000\n",
        "history = model4.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.15)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 386750 samples, validate on 68250 samples\n",
            "Epoch 1/5\n",
            "386750/386750 [==============================] - 576s 1ms/step - loss: 3.4836 - acc: 0.4692 - val_loss: 9.6990 - val_acc: 0.3983\n",
            "Epoch 2/5\n",
            "386750/386750 [==============================] - 572s 1ms/step - loss: 0.4626 - acc: 0.3981 - val_loss: 1.1921e-07 - val_acc: 0.3983\n",
            "Epoch 3/5\n",
            "386750/386750 [==============================] - 574s 1ms/step - loss: 1.1921e-07 - acc: 0.4002 - val_loss: 1.1921e-07 - val_acc: 0.3983\n",
            "Epoch 4/5\n",
            "386750/386750 [==============================] - 576s 1ms/step - loss: 1.1921e-07 - acc: 0.4002 - val_loss: 1.1921e-07 - val_acc: 0.3983\n",
            "Epoch 5/5\n",
            "386750/386750 [==============================] - 575s 1ms/step - loss: 1.1921e-07 - acc: 0.4002 - val_loss: 1.1921e-07 - val_acc: 0.3983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ2XxBb8FXR7",
        "colab_type": "code",
        "outputId": "6d2be1e6-05d6-425f-a1bb-63518921153c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#q. Score the test data using the LSTM model with regularization\n",
        "accr4 = model4.evaluate(X_test,Y_test, batch_size=1000)\n",
        "print('Test set\\n  Loss: {:0.9f}\\n  Accuracy: {:0.9f}'.format(accr4[0],accr4[1]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195000/195000 [==============================] - 94s 480us/step\n",
            "Test set\n",
            "  Loss: 0.000000119\n",
            "  Accuracy: 0.400271795\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}